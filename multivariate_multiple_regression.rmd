---
title: "Multivariate Multiple Regression"
output: html_document
---

```{r setup}
options(scipen = 999)
library(purrr)
library(dplyr)
library(data.table)
```


## Goal

Here we will perform a multivariate multiple regression analysis to predict player salary based on basketball in-game statistics

## Data

Read in the salary and player data.

```{r, eval=FALSE}
# list files in data/salary/src directory
dir <- "data/salary/src"
salary_files_tmp <- list.files(dir)
salary_files <- paste0(dir, "/", salary_files_tmp)

# read in salary data
salary_df <- map_df(salary_files, fread) %>% 
    as_tibble()

head(salary_df)
```

```{r, eval=FALSE}
# list files in data/gamelog/src directory
dir <- "data/gamelog/src/gamelogs/"
gamelog_files_tmp <- list.files(dir)
# remove files that start with a number
gamelog_files_tmp <- gamelog_files_tmp[!grepl("^[0-9]", gamelog_files_tmp)]
gamelog_files <- paste0(dir, "/", gamelog_files_tmp)

# read in gamelog data
# cast the GS column to character to avoid errors
gamelog_df <- map_df(gamelog_files, ~fread(.x) %>% mutate(across(.fns = as.character))) %>%
    as_tibble()

head(gamelog_df)
```

We merge the two data sets on player id.

```{r, eval=FALSE}
# merge the two data sets
df <- gamelog_df %>% 
    inner_join(salary_df, by = c("player" = "player_id"))

head(df)
```

Since the salary is a season-level statistic, we calculate season-level statistics for the game-level in-game statistics. 

```{r, eval=FALSE}
per_season_data_tmp <- df %>% 
    mutate(
        Age = substr(Age, 1, 2), # get first two characters of age to make numeric
        # convert salary to numeric, parsing out the $ and commas
        Salary = as.numeric(gsub("[$,]", "", Salary))
    ) %>%
    group_by(player,Season) %>%
    summarize(
        Age = mean(as.numeric(Age)),
        Tm = first(Tm),
        Team = first(Team),
        G = sum(as.numeric(G), na.rm = TRUE),
        GS = sum(as.numeric(GS), na.rm = TRUE),
        MP = mean(as.numeric(MP), na.rm = TRUE),
        FG = mean(as.numeric(FG), na.rm = TRUE),
        FGA = mean(as.numeric(FGA), na.rm = TRUE),
        `FG%` = mean(as.numeric(`FG%`), na.rm = TRUE),
        `3P` = mean(as.numeric(`3P`), na.rm = TRUE),
        `3PA` = mean(as.numeric(`3PA`), na.rm = TRUE),
        `3P%` = mean(as.numeric(`3P%`), na.rm = TRUE),
        FT = mean(as.numeric(FT), na.rm = TRUE),
        FTA = mean(as.numeric(FTA), na.rm = TRUE),
        `FT%` = mean(as.numeric(`FT%`), na.rm = TRUE),
        ORB = mean(as.numeric(ORB), na.rm = TRUE),
        DRB = mean(as.numeric(DRB), na.rm = TRUE),
        TRB = mean(as.numeric(TRB), na.rm = TRUE),
        AST = mean(as.numeric(AST), na.rm = TRUE),
        STL = mean(as.numeric(STL), na.rm = TRUE),
        BLK = mean(as.numeric(BLK), na.rm = TRUE),
        TOV = mean(as.numeric(TOV), na.rm = TRUE),
        PF = mean(as.numeric(PF), na.rm = TRUE),
        PTS = mean(as.numeric(PTS), na.rm = TRUE),
        Salary = mean(Salary, na.rm = TRUE)
    )

head(per_season_data_tmp)

# write tp csv
readr::write_csv(per_season_data_tmp, "data/per_season_data.csv")
```

## Exploratory Data Analysis

### Multivariate Normality

We recall from lecture that one of the assumptions of linear regression is that the data is multivariate normal. This distribution is characterized by the following properties:

1. The marginal distribution of each variable is normal
2. The joint distribution of pairs of variables are normal

These are very helpful because they allow us to check for multivariate normality by checking for univariate normality, rather than considering the challenging task of checking for multivariate normality directly.

We now consider the univeriate cases. We plot the distribution of each numeric column and the salary column in order to visually inspect the distribution. Then, we use the Shapiro-Wilk test to test for normality and check if this matches our visual inspection.

```{r}
# read the data from csv
per_season_data <- readr::read_csv("data/per_season_data.csv")

# create a list of numeric columns
num_cols <- per_season_data %>% 
    select(where(is.numeric)) %>% 
    names()

# plot the distribution of each numeric column
for (col in num_cols) {
    hist(per_season_data[[col]], main = col)
}

# plot the distribution of the salary
hist(per_season_data$Salary, main = "Salary")
```

```{r}
# shapiro wilk test
for (col in num_cols) {
    print(col)
    print(shapiro.test(per_season_data[[col]]))
}
```

We see clearly that many of the variables are not normally distributed and will need to be transformed. Furthermore, the salary distribution features a long tail, with substantial outliers. 

## Transformations

Depending on the skewness of the data, we can consider polynomial transformations and log transformations. We will consider the following transformations:

```{r}
```

## Multivariate Multiple Regression Regression

Now that the data is more suitable for our regression task, we can perform the regression. First, we discuss the characteristics of multivariate multiple regression.

Most notably, multivariate multiple regression is a generalization of multiple regression. In multiple regression, we have a single response variable and multiple predictor variables. In multivariate multiple regression, we have multiple response variables and multiple predictor variables. 

```{r}
```

### Model Selection

We can use several methods to help us choose the best model. It is preferable to include the least number of predictor variables possible, in order to have an explanable model, avoid overfitting, etc, but to balance this with the need to have a model that is sufficiently accurate. 

For example, we may use the AIC, BIC, or adjusted R-squared to help us choose the best model. 

```{r}
```


